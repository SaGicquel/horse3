"""
üèá API de Pr√©diction de Courses Hippiques
==========================================

API REST FastAPI pour servir le mod√®le XGBoost Champion (ROC-AUC Test: 0.6189, Backtest ROI: 22.71%).

Endpoints:
- POST /predict : Pr√©dire les probabilit√©s de victoire pour une course
- GET /health : V√©rifier l'√©tat de l'API
- GET /metrics : M√©triques Prometheus pour monitoring
- POST /feedback : Soumettre r√©sultats r√©els (Phase 8 - Online Learning)
- GET /feedback/stats : Statistiques feedback collect√©
- GET /feedback/model-performance : Performance mod√®le vs r√©alit√©

Auteur: Phase 7-8 - Production & Online Learning
Date: 2025-11-13
"""

import os
import sys
import time
import pickle
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

import pandas as pd
import numpy as np
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field, validator
import uvicorn
from api_phase9 import ModelServer as GNNServer
from ai_assistant import HorseRacingAssistant

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# MOD√àLES PYDANTIC (Validation entr√©es/sorties)
# ============================================================================

class ChevalFeatures(BaseModel):
    """Features d'un cheval participant √† une course."""
    
    # Identifiants
    cheval_id: str = Field(..., description="ID unique du cheval")
    jockey_id: Optional[int] = Field(None, description="ID du jockey (pour GNN)")
    entraineur_id: Optional[int] = Field(None, description="ID de l'entra√Æneur (pour GNN)")
    numero_partant: int = Field(..., ge=1, le=30, description="Num√©ro de d√©part (1-30)")
    
    # Features de forme (calcul√©es sur historique)
    forme_5c: float = Field(default=0.0, ge=0, le=1, description="Forme sur 5 derni√®res courses (0-1)")
    forme_10c: float = Field(default=0.0, ge=0, le=1, description="Forme sur 10 derni√®res courses (0-1)")
    nb_courses_12m: int = Field(default=0, ge=0, description="Nombre de courses 12 derniers mois")
    nb_victoires_12m: int = Field(default=0, ge=0, description="Nombre de victoires 12 derniers mois")
    nb_places_12m: int = Field(default=0, ge=0, description="Nombre de places (top 3) 12 derniers mois")
    recence: float = Field(default=90.0, ge=0, description="Jours depuis derni√®re course")
    regularite: float = Field(default=0.0, ge=0, le=1, description="R√©gularit√© performances (0-1)")
    
    # Features d'aptitude
    aptitude_distance: float = Field(default=0.0, ge=0, le=1, description="Performance sur cette distance")
    aptitude_piste: float = Field(default=0.0, ge=0, le=1, description="Performance sur ce type de piste")
    aptitude_hippodrome: float = Field(default=0.0, ge=0, le=1, description="Performance sur cet hippodrome")
    
    # Features jockey/entra√Æneur
    taux_victoires_jockey: float = Field(default=0.0, ge=0, le=1, description="Taux de victoire du jockey")
    taux_places_jockey: float = Field(default=0.0, ge=0, le=1, description="Taux de places du jockey")
    taux_victoires_entraineur: float = Field(default=0.0, ge=0, le=1, description="Taux de victoire entra√Æneur")
    taux_places_entraineur: float = Field(default=0.0, ge=0, le=1, description="Taux de places entra√Æneur")
    synergie_jockey_cheval: float = Field(default=0.0, ge=0, le=1, description="Synergie jockey-cheval")
    synergie_entraineur_cheval: float = Field(default=0.0, ge=0, le=1, description="Synergie entra√Æneur-cheval")
    
    # Features de course
    distance_norm: float = Field(default=0.0, ge=0, le=1, description="Distance normalis√©e (0-1)")
    niveau_moyen_concurrent: float = Field(default=0.0, ge=0, description="Niveau moyen adversaires")
    nb_partants: int = Field(default=10, ge=2, le=30, description="Nombre de partants dans la course")
    
    # Features march√© (optionnelles - peuvent √™tre absentes avant course)
    cote_turfbzh: Optional[float] = Field(None, ge=1.0, description="Cote TurfBZH (si disponible)")
    rang_cote_turfbzh: Optional[float] = Field(None, ge=1, description="Rang selon cote TurfBZH")
    cote_sp: Optional[float] = Field(None, ge=1.0, description="Cote StartingPrice PMU")
    rang_cote_sp: Optional[float] = Field(None, ge=1, description="Rang selon cote SP")
    prediction_ia_gagnant: Optional[float] = Field(None, ge=0, le=1, description="Pr√©diction IA du bookmaker")
    elo_cheval: Optional[float] = Field(None, ge=0, description="Score ELO du cheval")
    ecart_cote_ia: Optional[float] = Field(None, description="√âcart entre cote et pr√©diction IA")
    
    @validator('forme_5c', 'forme_10c', 'aptitude_distance', 'aptitude_piste', 'aptitude_hippodrome',
               'taux_victoires_jockey', 'taux_places_jockey', 'synergie_jockey_cheval', pre=True)
    def validate_probabilities(cls, v):
        """Valide que les probabilit√©s sont entre 0 et 1."""
        if v is not None and (v < 0 or v > 1):
            raise ValueError(f"Valeur doit √™tre entre 0 et 1, re√ßu: {v}")
        return v


class CourseRequest(BaseModel):
    """Requ√™te de pr√©diction pour une course compl√®te."""
    
    course_id: str = Field(..., description="ID unique de la course")
    date_course: str = Field(..., description="Date de la course (YYYY-MM-DD)")
    hippodrome: str = Field(..., description="Nom de l'hippodrome")
    distance: int = Field(..., ge=800, le=8000, description="Distance en m√®tres")
    type_piste: str = Field(..., description="Type de piste (Plat, Obstacle, etc.)")
    partants: List[ChevalFeatures] = Field(..., min_items=2, max_items=30, description="Liste des chevaux")
    
    @validator('date_course')
    def validate_date(cls, v):
        """Valide le format de date."""
        try:
            datetime.strptime(v, '%Y-%m-%d')
        except ValueError:
            raise ValueError("Format date invalide, attendu: YYYY-MM-DD")
        return v
    
    @validator('partants')
    def validate_unique_numbers(cls, v):
        """V√©rifie que les num√©ros de partants sont uniques."""
        numbers = [p.numero_partant for p in v]
        if len(numbers) != len(set(numbers)):
            raise ValueError("Les num√©ros de partants doivent √™tre uniques")
        return v


class PredictionCheval(BaseModel):
    """Pr√©diction pour un cheval."""
    cheval_id: str
    numero_partant: int
    probabilite_victoire: float = Field(..., ge=0, le=1, description="P(victoire) pr√©dite par le mod√®le")
    rang_prediction: int = Field(..., ge=1, description="Rang selon pr√©diction (1=favori)")
    confiance: str = Field(..., description="Niveau de confiance (Haute/Moyenne/Faible)")


class PredictionResponse(BaseModel):
    """R√©ponse de pr√©diction pour une course."""
    course_id: str
    timestamp: str
    model_version: str
    top_3: List[PredictionCheval] = Field(..., description="Top 3 des favoris selon le mod√®le")
    toutes_predictions: List[PredictionCheval] = Field(..., description="Pr√©dictions pour tous les partants")
    latence_ms: float = Field(..., description="Temps de calcul en millisecondes")


class ChatMessage(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    message: str
    history: List[ChatMessage] = []

class ChatResponse(BaseModel):
    response: str
    timestamp: str


class HealthResponse(BaseModel):
    """R√©ponse du healthcheck."""
    status: str
    model_loaded: bool
    model_version: str
    uptime_seconds: float
    total_predictions: int


# ============================================================================
# CLASSE GESTIONNAIRE DE MOD√àLE
# ============================================================================

class ModelManager:
    """G√®re le chargement et l'utilisation du mod√®le ML."""
    
    def __init__(self, model_path: str, challenger_path: Optional[str] = None):
        self.model_path = Path(model_path)
        self.model = None
        self.feature_names = None
        self.model_version = "xgboost_champion_v1.0"
        self.loaded_at = None
        
        # A/B Testing support (Phase 8)
        self.challenger_path = Path(challenger_path) if challenger_path else None
        self.challenger_model = None
        self.challenger_version = None
        self.ab_test_enabled = os.getenv('AB_TEST_ENABLED', 'false').lower() == 'true'
        self.challenger_traffic_percent = float(os.getenv('CHALLENGER_TRAFFIC_PERCENT', '10'))
        
        # Compteurs pour monitoring
        self.total_predictions = 0
        self.total_latency_ms = 0.0
        self.champion_predictions = 0
        self.challenger_predictions = 0
        
        # GNN Server (Phase 9)
        self.gnn_server = None
        
        # Features attendues (62 features apr√®s exclusion position_arrivee)
        self.expected_features = [
            # Forme (7)
            'forme_5c', 'forme_10c', 'nb_courses_12m', 'nb_victoires_12m',
            'nb_places_12m', 'recence', 'regularite',
            # Aptitude (3)
            'aptitude_distance', 'aptitude_piste', 'aptitude_hippodrome',
            # Jockey/Entraineur (6)
            'taux_victoires_jockey', 'taux_places_jockey',
            'taux_victoires_entraineur', 'taux_places_entraineur',
            'synergie_jockey_cheval', 'synergie_entraineur_cheval',
            # Course (3)
            'distance_norm', 'niveau_moyen_concurrent', 'nb_partants',
            # March√© (5 - optionnelles)
            'cote_turfbzh', 'rang_cote_turfbzh', 'cote_sp', 'rang_cote_sp',
            'prediction_ia_gagnant', 'elo_cheval', 'ecart_cote_ia'
        ]
    
    def load_model(self) -> bool:
        """Charge le mod√®le champion (et challenger si A/B testing activ√©)."""
        try:
            # Chargement champion
            if not self.model_path.exists():
                logger.error(f"‚ùå Mod√®le champion introuvable: {self.model_path}")
                return False
            
            logger.info(f"üì¶ Chargement mod√®le champion depuis {self.model_path}...")
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
            
            self.loaded_at = datetime.now()
            logger.info(f"‚úÖ Mod√®le champion charg√©: {self.model_version}")
            logger.info(f"   Type: {type(self.model).__name__}")
            
            # R√©cup√©rer les noms de features si disponible
            if hasattr(self.model, 'feature_names_in_'):
                self.feature_names = list(self.model.feature_names_in_)
                logger.info(f"   Features: {len(self.feature_names)}")
            
            # Chargement challenger si A/B testing activ√©
            if self.ab_test_enabled:
                logger.info("üî¨ Tentative chargement GNN (Challenger Phase 9)...")
                try:
                    self.gnn_server = GNNServer()
                    self.gnn_server.load_resources()
                    self.challenger_model = self.gnn_server # Marker
                    self.challenger_version = "gnn_v1"
                    logger.info(f"‚úÖ Mod√®le GNN charg√©: {self.challenger_version}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  √âchec chargement GNN: {e}")
                    # Fallback sur ancien challenger si path existe
                    if self.challenger_path and self.challenger_path.exists():
                        logger.info(f"üî¨ Chargement mod√®le challenger legacy depuis {self.challenger_path}...")
                        try:
                            with open(self.challenger_path, 'rb') as f:
                                self.challenger_model = pickle.load(f)
                            self.challenger_version = "challenger_legacy"
                            logger.info(f"‚úÖ Mod√®le challenger legacy charg√©")
                        except Exception as ex:
                            logger.warning(f"‚ö†Ô∏è  √âchec chargement challenger legacy: {ex}")
                            self.challenger_model = None
                    else:
                        self.challenger_model = None

            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le: {e}", exc_info=True)
            return False
    
    def prepare_features(self, partants: List[ChevalFeatures]) -> pd.DataFrame:
        """Convertit les features Pydantic en DataFrame pour le mod√®le."""
        
        data = []
        for cheval in partants:
            # Convertir Pydantic model en dict
            features = cheval.dict()
            
            # Remplir les valeurs manquantes (features march√© optionnelles)
            for feat in ['cote_turfbzh', 'rang_cote_turfbzh', 'cote_sp', 'rang_cote_sp',
                        'prediction_ia_gagnant', 'elo_cheval', 'ecart_cote_ia']:
                if features[feat] is None:
                    features[feat] = 0.0
            
            data.append(features)
        
        df = pd.DataFrame(data)
        
        # S√©lectionner uniquement les features attendues par le mod√®le
        if self.feature_names:
            # Utiliser l'ordre exact des features du mod√®le
            missing_features = set(self.feature_names) - set(df.columns)
            if missing_features:
                logger.warning(f"‚ö†Ô∏è  Features manquantes: {missing_features}")
                for feat in missing_features:
                    df[feat] = 0.0
            
            df = df[self.feature_names]
        else:
            # Fallback: utiliser expected_features
            available = [f for f in self.expected_features if f in df.columns]
            df = df[available]
        
        return df
    
    def select_model_ab_test(self) -> tuple:
        """
        S√©lectionne le mod√®le √† utiliser selon strat√©gie A/B testing.
        
        Returns:
            (model, model_version) tuple
        """
        # Si A/B testing d√©sactiv√© ou pas de challenger, utiliser champion
        if not self.ab_test_enabled or self.challenger_model is None:
            return self.model, self.model_version
        
        # Tirer au sort selon pourcentage configur√©
        random_value = np.random.random() * 100
        
        if random_value < self.challenger_traffic_percent:
            # Utiliser challenger
            self.challenger_predictions += 1
            logger.info(f"üî¨ A/B Test: Utilisation challenger ({self.challenger_version})")
            return self.challenger_model, self.challenger_version
        else:
            # Utiliser champion
            self.champion_predictions += 1
            return self.model, self.model_version
    
    def predict(self, partants: List[ChevalFeatures]) -> tuple:
        """
        Pr√©dit les probabilit√©s de victoire pour une liste de partants.
        Support A/B testing champion vs challenger (Phase 8).
        
        Returns:
            (predictions, latency_ms, model_version) tuple
        """
        start_time = time.time()
        
        try:
            # Pr√©parer features
            X = self.prepare_features(partants)
            
            # S√©lectionner mod√®le (A/B testing)
            selected_model, selected_version = self.select_model_ab_test()
            
            # Logique sp√©cifique pour le GNN (Phase 9)
            if selected_version == "gnn_v1":
                predictions = []
                for cheval in partants:
                    # V√©rifier pr√©sence des IDs
                    if cheval.jockey_id is None or cheval.entraineur_id is None:
                        # Fallback silencieux sur le champion si IDs manquants
                        logger.warning(f"‚ö†Ô∏è IDs manquants pour GNN (cheval {cheval.cheval_id}), fallback Champion")
                        selected_model = self.model
                        selected_version = self.model_version
                        break # Sortir de la boucle et utiliser logique standard
                    
                    # Conversion str -> int si n√©cessaire (le mod√®le attend des int)
                    try:
                        h_id = int(cheval.cheval_id)
                        j_id = int(cheval.jockey_id)
                        e_id = int(cheval.entraineur_id)
                        
                        score, status = selected_model.predict(h_id, j_id, e_id)
                        
                        if score is None:
                            score = 0.0 # Ou fallback
                            
                        predictions.append({
                            'cheval_id': cheval.cheval_id,
                            'numero_partant': cheval.numero_partant,
                            'probabilite_victoire': float(score)
                        })
                    except ValueError:
                        logger.error(f"‚ùå IDs invalides pour GNN: {cheval.cheval_id}")
                        selected_model = self.model
                        selected_version = self.model_version
                        break

                # Si on a r√©ussi √† pr√©dire avec le GNN pour tous les partants
                if selected_version == "gnn_v1":
                    # Normalisation Softmax (optionnel mais recommand√© pour avoir des probas qui somment √† 1)
                    # Le GNN sort des logits ou des sigmoids ind√©pendants.
                    # Ici on a des sigmoids (0-1). On peut les normaliser.
                    scores = np.array([p['probabilite_victoire'] for p in predictions])
                    if scores.sum() > 0:
                        scores = scores / scores.sum()
                    for i, p in enumerate(predictions):
                        p['probabilite_victoire'] = float(scores[i])
            
            # Logique Standard (Champion / Legacy Challenger)
            if selected_version != "gnn_v1":
                # Pr√©dire probabilit√©s avec le mod√®le s√©lectionn√©
                probas = selected_model.predict_proba(X)[:, 1]  # Proba classe 1 (victoire)
                
                predictions = []
                for i, (cheval, proba) in enumerate(zip(partants, probas)):
                    predictions.append({
                        'cheval_id': cheval.cheval_id,
                        'numero_partant': cheval.numero_partant,
                        'probabilite_victoire': float(proba)
                    })
            
            # Trier par probabilit√© d√©croissante
            
            # Trier par probabilit√© d√©croissante
            predictions.sort(key=lambda x: x['probabilite_victoire'], reverse=True)
            
            # Ajouter rangs
            for rank, pred in enumerate(predictions, 1):
                pred['rang_prediction'] = rank
                
                # Niveau de confiance bas√© sur probabilit√©
                if pred['probabilite_victoire'] >= 0.3:
                    pred['confiance'] = 'Haute'
                elif pred['probabilite_victoire'] >= 0.15:
                    pred['confiance'] = 'Moyenne'
                else:
                    pred['confiance'] = 'Faible'
            
            # Mise √† jour m√©triques
            latency_ms = (time.time() - start_time) * 1000
            self.total_predictions += len(partants)
            self.total_latency_ms += latency_ms
            
            logger.info(f"‚úÖ Pr√©diction r√©ussie: {len(partants)} chevaux en {latency_ms:.1f}ms (mod√®le: {selected_version})")
            
            return predictions, latency_ms, selected_version
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"Erreur pr√©diction: {str(e)}")
    
    def get_uptime(self) -> float:
        """Retourne le temps d'activit√© en secondes."""
        if self.loaded_at:
            return (datetime.now() - self.loaded_at).total_seconds()
        return 0.0
    
    def get_avg_latency(self) -> float:
        """Retourne la latence moyenne en millisecondes."""
        if self.total_predictions > 0:
            return self.total_latency_ms / self.total_predictions
        return 0.0


# ============================================================================
# INITIALISATION FASTAPI
# ============================================================================

# Cr√©er l'application
app = FastAPI(
    title="üèá API Pr√©diction Courses Hippiques",
    description="API pour pr√©dire les probabilit√©s de victoire avec Stacking Ensemble (ROC-AUC Test: 0.7009)",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS (permettre appels depuis frontend)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # √Ä restreindre en production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gestionnaire de mod√®le (global)
model_manager: Optional[ModelManager] = None

# Gestionnaire de feedback (Phase 8 - Online Learning)
from api_feedback import (
    FeedbackManager, CourseResult, FeedbackResponse,
    FeedbackStats, ModelPerformance
)
feedback_manager = FeedbackManager()

# Assistant IA (Chat)
chat_assistant: Optional[HorseRacingAssistant] = None


@app.on_event("startup")
async def startup_event():
    """√âv√©nement de d√©marrage: charge le mod√®le champion (et challenger si A/B testing)."""
    global model_manager, chat_assistant
    
    logger.info("=" * 80)
    logger.info("üöÄ D√âMARRAGE API PR√âDICTION")
    logger.info("=" * 80)
    
    # Initialisation de l'assistant IA
    chat_assistant = HorseRacingAssistant()
    logger.info("ü§ñ Assistant IA initialis√©")
    
    # Chemin vers le mod√®le champion (configurable via env var)
    champion_path = os.getenv('MODEL_PATH', 'data/models/champion/xgboost_model.pkl')
    
    # Chemin vers le mod√®le challenger (optionnel, pour A/B testing)
    challenger_path = os.getenv('CHALLENGER_MODEL_PATH', 'data/models/challenger/model.pkl')
    
    model_manager = ModelManager(champion_path, challenger_path)
    
    if not model_manager.load_model():
        logger.error("‚ùå √âCHEC CHARGEMENT MOD√àLE - API en mode d√©grad√©")
    else:
        logger.info("‚úÖ API pr√™te √† recevoir des requ√™tes")
    
    logger.info("=" * 80)


# ============================================================================
# ENDPOINTS
# ============================================================================

@app.get("/", tags=["Info"])
async def root():
    """Page d'accueil de l'API."""
    return {
        "message": "üèá API Pr√©diction Courses Hippiques",
        "version": "1.0.0",
        "model": "Stacking Ensemble (RF + XGBoost + LightGBM)",
        "performance": "ROC-AUC Test: 0.7009",
        "endpoints": {
            "predict": "POST /predict - Pr√©dire une course",
            "health": "GET /health - √âtat de l'API",
            "metrics": "GET /metrics - M√©triques monitoring",
            "docs": "GET /docs - Documentation interactive"
        }
    }


@app.get("/health", response_model=HealthResponse, tags=["Monitoring"])
async def health_check():
    """
    Healthcheck pour v√©rifier l'√©tat de l'API.
    Utilis√© par Kubernetes/Docker pour liveness/readiness probes.
    """
    if model_manager is None or model_manager.model is None:
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "model_loaded": False,
                "model_version": "N/A",
                "uptime_seconds": 0.0,
                "total_predictions": 0
            }
        )
    
    return HealthResponse(
        status="healthy",
        model_loaded=True,
        model_version=model_manager.model_version,
        uptime_seconds=model_manager.get_uptime(),
        total_predictions=model_manager.total_predictions
    )


@app.get("/metrics", tags=["Monitoring"])
async def metrics():
    """
    M√©triques Prometheus pour monitoring.
    Format: nom_metrique{label="value"} valeur
    """
    if model_manager is None:
        return ""
    
    metrics_text = f"""# HELP predictions_total Nombre total de pr√©dictions effectu√©es
# TYPE predictions_total counter
predictions_total {model_manager.total_predictions}

# HELP predictions_by_model Nombre de pr√©dictions par mod√®le (A/B testing)
# TYPE predictions_by_model counter
predictions_by_model{{model_version="champion"}} {model_manager.champion_predictions}
predictions_by_model{{model_version="challenger"}} {model_manager.challenger_predictions}

# HELP prediction_latency_ms Latence moyenne de pr√©diction en millisecondes
# TYPE prediction_latency_ms gauge
prediction_latency_ms {model_manager.get_avg_latency():.2f}

# HELP api_uptime_seconds Temps d'activit√© de l'API en secondes
# TYPE api_uptime_seconds gauge
api_uptime_seconds {model_manager.get_uptime():.1f}

# HELP model_loaded Mod√®le charg√© (1) ou non (0)
# TYPE model_loaded gauge
model_loaded {1 if model_manager.model else 0}

# HELP ab_test_enabled A/B testing activ√© (1) ou non (0)
# TYPE ab_test_enabled gauge
ab_test_enabled {1 if model_manager.ab_test_enabled and model_manager.challenger_model else 0}

# HELP challenger_traffic_percent Pourcentage de traffic vers challenger
# TYPE challenger_traffic_percent gauge
challenger_traffic_percent {model_manager.challenger_traffic_percent if model_manager.ab_test_enabled else 0}
"""
    
    return metrics_text


@app.post("/predict", response_model=PredictionResponse, tags=["Pr√©diction"])
async def predict_course(request: CourseRequest):
    """
    Pr√©dit les probabilit√©s de victoire pour tous les partants d'une course.
    
    Args:
        request: CourseRequest avec course_id, date, hippodrome et liste des partants
    
    Returns:
        PredictionResponse avec top 3 + toutes pr√©dictions + m√©tadonn√©es
    
    Raises:
        HTTPException 503: Mod√®le non charg√©
        HTTPException 400: Requ√™te invalide
        HTTPException 500: Erreur interne
    """
    # V√©rifier que le mod√®le est charg√©
    if model_manager is None or model_manager.model is None:
        raise HTTPException(
            status_code=503,
            detail="Mod√®le non charg√©. Veuillez contacter l'administrateur."
        )
    
    # Log de la requ√™te
    logger.info(f"üì• Nouvelle pr√©diction: course={request.course_id}, "
               f"hippodrome={request.hippodrome}, partants={len(request.partants)}")
    
    try:
        # Pr√©dire (avec A/B testing si activ√©)
        predictions, latency_ms, model_version = model_manager.predict(request.partants)
        
        # Convertir en Pydantic models
        all_predictions = [PredictionCheval(**pred) for pred in predictions]
        top_3 = all_predictions[:3]
        
        # Cr√©er r√©ponse
        response = PredictionResponse(
            course_id=request.course_id,
            timestamp=datetime.now().isoformat(),
            model_version=model_version,  # Version du mod√®le utilis√© (champion ou challenger)
            top_3=top_3,
            toutes_predictions=all_predictions,
            latence_ms=latency_ms
        )
        
        logger.info(f"‚úÖ Pr√©diction envoy√©e: top_3=[{', '.join(str(p.numero_partant) for p in top_3)}], "
                   f"latence={latency_ms:.1f}ms")
        
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur pr√©diction: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la pr√©diction: {str(e)}")


# ============================================================================
# ENDPOINTS - PHASE 8 : ONLINE LEARNING & FEEDBACK
# ============================================================================

@app.post("/feedback", response_model=FeedbackResponse, tags=["Feedback"])
async def submit_feedback(course_result: CourseResult):
    """
    üìù Enregistrer le r√©sultat r√©el d'une course pour am√©liorer le mod√®le.
    
    Permet de collecter les positions d'arriv√©e r√©elles et comparer avec les pr√©dictions
    pour retrainer automatiquement le mod√®le (online learning).
    
    Args:
        course_result: CourseResult avec course_id et positions d'arriv√©e
    
    Returns:
        FeedbackResponse avec statut de l'enregistrement
    
    Raises:
        HTTPException 400: Donn√©es invalides
        HTTPException 500: Erreur interne
        
    Exemple:
    ```json
    {
        "course_id": "VINCENNES_2025-11-13_R1C3",
        "date_course": "2025-11-13",
        "hippodrome": "VINCENNES",
        "resultats": [
            {"cheval_id": "CHEVAL_001", "numero_partant": 1, "position_arrivee": 3},
            {"cheval_id": "CHEVAL_002", "numero_partant": 2, "position_arrivee": 1}
        ]
    }
    ```
    """
    try:
        response = feedback_manager.save_feedback(course_result)
        
        logger.info(f"üìù Feedback enregistr√©: course={course_result.course_id}, "
                   f"nb_chevaux={len(course_result.resultats)}")
        
        return response
        
    except ValueError as e:
        # Erreur de validation
        logger.warning(f"‚ö†Ô∏è Feedback invalide: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"‚ùå Erreur feedback: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'enregistrement: {str(e)}")


@app.get("/feedback/stats", response_model=FeedbackStats, tags=["Feedback"])
async def get_feedback_stats():
    """
    üìä R√©cup√©rer les statistiques du feedback collect√©.
    
    Affiche le nombre de courses et pr√©dictions avec feedback, la p√©riode couverte,
    et le taux de collection.
    
    Returns:
        FeedbackStats avec m√©triques de collection
        
    Exemple de r√©ponse:
    ```json
    {
        "total_courses": 150,
        "total_predictions": 1234,
        "periode_debut": "2025-10-01",
        "periode_fin": "2025-11-13",
        "nb_courses_last_7d": 25,
        "nb_courses_last_30d": 89,
        "taux_collection": 0.65
    }
    ```
    """
    try:
        stats = feedback_manager.get_stats()
        
        logger.info(f"üìä Stats feedback r√©cup√©r√©es: courses={stats.total_courses}, "
                   f"predictions={stats.total_predictions}")
        
        return stats
        
    except Exception as e:
        logger.error(f"‚ùå Erreur stats feedback: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors de la r√©cup√©ration: {str(e)}")


@app.get("/feedback/model-performance", response_model=ModelPerformance, tags=["Feedback"])
async def get_model_performance(days: int = 7):
    """
    üéØ Analyser la performance du mod√®le sur les N derniers jours.
    
    Compare les pr√©dictions du mod√®le avec les r√©sultats r√©els pour calculer:
    - Accuracy top 1 (% gagnants pr√©dits correctement)
    - Accuracy top 3 (% podiums pr√©dits correctement)
    - Brier Score (calibration des probabilit√©s)
    - Expected Calibration Error (ECE)
    
    Args:
        days: Nombre de jours √† analyser (d√©faut: 7, min: 1, max: 90)
    
    Returns:
        ModelPerformance avec m√©triques de performance r√©elles
        
    Raises:
        HTTPException 400: Param√®tre days invalide
        HTTPException 500: Erreur interne
        
    Exemple:
    ```
    GET /feedback/model-performance?days=30
    ```
    
    R√©ponse:
    ```json
    {
        "periode": "30 derniers jours",
        "nb_courses": 120,
        "nb_predictions": 987,
        "accuracy_top1": 0.28,
        "nb_correct_top1": 34,
        "accuracy_top3": 0.67,
        "nb_correct_top3": 80,
        "brier_score": 0.142,
        "ece": 0.065
    }
    ```
    """
    try:
        # Validation
        if days < 1 or days > 90:
            raise HTTPException(
                status_code=400, 
                detail="Le param√®tre 'days' doit √™tre entre 1 et 90"
            )
        
        performance = feedback_manager.get_model_performance(days=days)
        
        logger.info(f"üéØ Performance calcul√©e: p√©riode={days}j, courses={performance.nb_courses}, "
                   f"accuracy_top1={performance.accuracy_top1:.2%}")
        
        return performance
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur performance: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur lors du calcul: {str(e)}")


@app.post("/api/chat", response_model=ChatResponse, tags=["Assistant IA"])
async def chat_endpoint(request: ChatRequest):
    """
    Endpoint pour l'assistant IA.
    Traite le message de l'utilisateur et retourne une r√©ponse contextuelle.
    """
    try:
        if not chat_assistant:
            raise HTTPException(status_code=503, detail="Assistant IA non initialis√©")
            
        # Convertir les messages Pydantic en dict pour l'assistant
        history_dicts = [{"role": m.role, "content": m.content} for m in request.history]
        
        response_text = chat_assistant.process_message(request.message, history_dicts)
        
        return ChatResponse(
            response=response_text,
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        logger.error(f"‚ùå Erreur chat: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur assistant: {str(e)}")


# ============================================================================
# MAIN
# ============================================================================
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur interne: {str(e)}")


# ============================================================================
# POINT D'ENTR√âE
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="API de pr√©diction courses hippiques")
    parser.add_argument('--host', type=str, default='0.0.0.0', help='Host (d√©faut: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=8000, help='Port (d√©faut: 8000)')
    parser.add_argument('--reload', action='store_true', help='Auto-reload en dev')
    parser.add_argument('--model-path', type=str, help='Chemin vers le mod√®le .pkl')
    
    args = parser.parse_args()
    
    # D√©finir MODEL_PATH si fourni
    if args.model_path:
        os.environ['MODEL_PATH'] = args.model_path
    
    # Lancer serveur
    uvicorn.run(
        "api_prediction:app",
        host=args.host,
        port=args.port,
        reload=args.reload,
        log_level="info"
    )
