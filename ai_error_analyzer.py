#!/usr/bin/env python3
"""
üîç AI Error Analyzer - Analyse les erreurs de pr√©diction avec Gemini
=====================================================================
Charge les pr√©dictions pass√©es, identifie les erreurs, et utilise Gemini
pour analyser pourquoi le mod√®le s'est tromp√©.

Usage:
    python ai_error_analyzer.py --zone micro
    python ai_error_analyzer.py --zone full --limit 50
    python ai_error_analyzer.py --all-zones
"""

import os
import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

import pandas as pd
import numpy as np

# Configuration
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("‚ùå GOOGLE_API_KEY non d√©finie")
    sys.exit(1)

# Import Gemini
from google import genai

client = genai.Client(api_key=GOOGLE_API_KEY)
MODEL_NAME = "gemini-2.0-flash"

# R√©pertoires
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = DATA_DIR / "models" / "zones"
REPORTS_DIR = BASE_DIR / "reports" / "ai_analysis"
REPORTS_DIR.mkdir(parents=True, exist_ok=True)


class AIErrorAnalyzer:
    """Analyse les erreurs de pr√©diction avec Gemini."""

    def __init__(self, zone: str):
        self.zone = zone
        self.zone_dir = MODELS_DIR / zone
        self.errors = []
        self.insights = []

        print(f"\n{'='*60}")
        print(f"üîç Analyse des erreurs - Zone {zone.upper()}")
        print(f"{'='*60}")

    def load_predictions(self, limit: int = 100) -> pd.DataFrame:
        """Charge les pr√©dictions r√©centes avec leurs r√©sultats."""
        print("\nüìä Chargement des pr√©dictions...")

        # Essayer de charger depuis un fichier de pr√©dictions
        pred_files = [
            DATA_DIR / f"predictions_{self.zone}.parquet",
            DATA_DIR / "predictions_history.parquet",
            DATA_DIR / "betting_history.csv",
        ]

        for f in pred_files:
            if f.exists():
                print(f"   Fichier: {f}")
                if f.suffix == ".parquet":
                    df = pd.read_parquet(f)
                else:
                    df = pd.read_csv(f)
                return df.tail(limit)

        # Sinon charger depuis la BDD
        return self._load_from_db(limit)

    def _load_from_db(self, limit: int) -> pd.DataFrame:
        """Charge les pr√©dictions depuis PostgreSQL."""
        try:
            from db_connection import get_connection

            conn = get_connection()
            query = f"""
                SELECT
                    b.id, b.created_at, b.selection, b.bet_type,
                    b.stake, b.odds, b.status, b.pnl,
                    b.race_key, b.hippodrome
                FROM user_bets b
                WHERE b.status IN ('WIN', 'LOSE')
                ORDER BY b.created_at DESC
                LIMIT {limit}
            """
            df = pd.read_sql(query, conn)
            conn.close()
            print(f"   Charg√©s: {len(df)} paris")
            return df
        except Exception as e:
            print(f"‚ö†Ô∏è  Pas de donn√©es en BDD: {e}")
            return self._generate_sample_data(limit)

    def _generate_sample_data(self, n: int = 50) -> pd.DataFrame:
        """G√©n√®re des donn√©es de test si pas de vraies donn√©es."""
        print("   ‚ö†Ô∏è  G√©n√©ration de donn√©es de test...")

        np.random.seed(42)

        data = []
        for i in range(n):
            is_win = np.random.random() < 0.35  # 35% win rate simul√©
            odds = np.random.uniform(1.5, 8.0)
            stake = np.random.choice([5, 10, 15, 20, 25])
            predicted_proba = np.random.uniform(0.1, 0.4)

            data.append(
                {
                    "id": i + 1,
                    "date": f"2024-12-{(i % 30) + 1:02d}",
                    "cheval": f"Cheval_{np.random.randint(1, 100)}",
                    "hippodrome": np.random.choice(
                        ["Vincennes", "Longchamp", "Auteuil", "Chantilly"]
                    ),
                    "discipline": np.random.choice(["Trot", "Galop", "Obstacle"]),
                    "bet_type": np.random.choice(["PLACE", "WIN", "E_P"]),
                    "cote": round(odds, 2),
                    "stake": stake,
                    "status": "WIN" if is_win else "LOSE",
                    "pnl": round(stake * (odds - 1) if is_win else -stake, 2),
                    "predicted_proba": round(predicted_proba, 3),
                    "actual_place": np.random.randint(1, 15),
                    "participants_count": np.random.randint(8, 16),
                    "favoris_rank": np.random.randint(1, 10),
                    "meteo": np.random.choice(["Soleil", "Nuageux", "Pluie", "Orageux"]),
                    "terrain": np.random.choice(["Bon", "Souple", "Lourd", "Tr√®s lourd"]),
                }
            )

        df = pd.DataFrame(data)
        print(f"   G√©n√©r√©s: {len(df)} paris simul√©s")
        return df

    def identify_errors(self, df: pd.DataFrame) -> List[Dict]:
        """Identifie les erreurs de pr√©diction."""
        print("\nüîç Identification des erreurs...")

        # Filtrer les erreurs (pr√©dit gagnant mais perdu)
        if "status" in df.columns:
            losses = df[df["status"] == "LOSE"].copy()
        else:
            losses = df[df["pnl"] < 0].copy()

        print(f"   Total paris: {len(df)}")
        print(f"   Erreurs (pertes): {len(losses)}")

        # Convertir en liste de dicts
        self.errors = losses.to_dict("records")
        return self.errors

    def analyze_with_gemini(self, errors: List[Dict], batch_size: int = 10) -> str:
        """Analyse les erreurs avec Gemini."""
        print(f"\nüß† Analyse avec Gemini ({len(errors)} erreurs)...")

        # Prendre un √©chantillon pour ne pas d√©passer les limites
        sample = errors[:batch_size]

        # Formatter les erreurs pour Gemini
        errors_text = json.dumps(sample, indent=2, ensure_ascii=False, default=str)

        prompt = f"""Tu es un expert en analyse de donn√©es de courses hippiques.

Voici {len(sample)} paris PERDANTS (le mod√®le a pr√©dit que ces chevaux seraient gagnants/plac√©s mais ils ont perdu):

```json
{errors_text}
```

Analyse ces erreurs et fournis:

## 1. Patterns Communs
Quels points communs ont ces paris perdants? (m√©t√©o, terrain, cotes, discipline, etc.)

## 2. Causes Probables
Pour chaque type d'erreur, explique pourquoi le mod√®le a pu se tromper.

## 3. Features Manquantes
Quelles informations auraient pu aider √† √©viter ces erreurs?

## 4. Recommandations Concr√®tes
Liste 5 am√©liorations sp√©cifiques √† apporter au mod√®le.

## 5. Code Sugg√©r√©
Propose du code Python pour ajouter une feature qui aurait pu d√©tecter ces erreurs.

Sois concis et actionnable."""

        try:
            response = client.models.generate_content(model=MODEL_NAME, contents=prompt)
            return response.text
        except Exception as e:
            return f"Erreur Gemini: {e}"

    def analyze_winning_patterns(self, df: pd.DataFrame) -> str:
        """Analyse les patterns des paris gagnants."""
        print("\n‚úÖ Analyse des paris gagnants...")

        if "status" in df.columns:
            wins = df[df["status"] == "WIN"].copy()
        else:
            wins = df[df["pnl"] > 0].copy()

        if len(wins) == 0:
            return "Pas de paris gagnants √† analyser."

        sample = wins.head(10).to_dict("records")
        wins_text = json.dumps(sample, indent=2, ensure_ascii=False, default=str)

        prompt = f"""Voici {len(sample)} paris GAGNANTS:

```json
{wins_text}
```

Analyse ces succ√®s et identifie:

## 1. Patterns de Succ√®s
Quels facteurs ont contribu√© √† ces victoires?

## 2. Conditions Favorables
Dans quelles conditions le mod√®le performe le mieux?

## 3. Features Importantes
Quelles features semblent les plus pr√©dictives?

Sois concis."""

        try:
            response = client.models.generate_content(model=MODEL_NAME, contents=prompt)
            return response.text
        except Exception as e:
            return f"Erreur Gemini: {e}"

    def generate_v2_recommendations(self, error_analysis: str, win_analysis: str) -> str:
        """G√©n√®re des recommandations pour le mod√®le V2."""
        print("\nüöÄ G√©n√©ration des recommandations V2...")

        prompt = f"""Bas√© sur ces analyses de paris hippiques:

## ANALYSE DES ERREURS:
{error_analysis[:2000]}

## ANALYSE DES SUCC√àS:
{win_analysis[:2000]}

G√©n√®re un plan d'am√©lioration pour le mod√®le V2:

## 1. Nouvelles Features √† Cr√©er
Liste 5 features avec leur code Python.

## 2. Modifications des Hyperparam√®tres
Quels ajustements faire √† XGBoost?

## 3. Filtres √† Ajouter
Quels paris √©viter selon les patterns d'erreur?

## 4. Pond√©ration
Comment ajuster les poids des features?

## 5. Code d'Impl√©mentation
Fournis le code Python complet pour impl√©menter ces am√©liorations.

Sois tr√®s concret et donne du code ex√©cutable."""

        try:
            response = client.models.generate_content(model=MODEL_NAME, contents=prompt)
            return response.text
        except Exception as e:
            return f"Erreur Gemini: {e}"

    def save_report(self, error_analysis: str, win_analysis: str, v2_reco: str) -> Path:
        """Sauvegarde le rapport d'analyse."""
        report_path = (
            REPORTS_DIR / f"analysis_{self.zone}_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
        )

        content = f"""# üîç Analyse IA - Zone {self.zone.upper()}
*G√©n√©r√© le {datetime.now().strftime('%Y-%m-%d %H:%M')}*

---

## Analyse des Erreurs
{error_analysis}

---

## Analyse des Succ√®s
{win_analysis}

---

## Recommandations V2
{v2_reco}
"""

        with open(report_path, "w") as f:
            f.write(content)

        print(f"\nüíæ Rapport sauvegard√©: {report_path}")
        return report_path

    def run(self, limit: int = 100) -> Dict[str, Any]:
        """Ex√©cute l'analyse compl√®te."""
        # Charger les pr√©dictions
        df = self.load_predictions(limit)

        if df is None or len(df) == 0:
            return {"success": False, "reason": "no_data"}

        # Identifier les erreurs
        errors = self.identify_errors(df)

        # Analyser les erreurs avec Gemini
        print("\n" + "-" * 40)
        error_analysis = self.analyze_with_gemini(errors)
        print(error_analysis[:500] + "..." if len(error_analysis) > 500 else error_analysis)

        # Analyser les succ√®s
        print("\n" + "-" * 40)
        win_analysis = self.analyze_winning_patterns(df)

        # G√©n√©rer recommandations V2
        print("\n" + "-" * 40)
        v2_recommendations = self.generate_v2_recommendations(error_analysis, win_analysis)

        # Sauvegarder le rapport
        report_path = self.save_report(error_analysis, win_analysis, v2_recommendations)

        return {
            "success": True,
            "zone": self.zone,
            "errors_count": len(errors),
            "report_path": str(report_path),
            "v2_recommendations": v2_recommendations[:1000],
        }


def main():
    parser = argparse.ArgumentParser(
        description="üîç AI Error Analyzer - Analyse les erreurs avec Gemini"
    )
    parser.add_argument("--zone", choices=["micro", "small", "full"], help="Zone √† analyser")
    parser.add_argument("--all-zones", action="store_true", help="Analyse toutes les zones")
    parser.add_argument("--limit", type=int, default=100, help="Nombre de paris √† analyser")

    args = parser.parse_args()

    if args.all_zones:
        for zone in ["micro", "small", "full"]:
            analyzer = AIErrorAnalyzer(zone)
            analyzer.run(args.limit)
    elif args.zone:
        analyzer = AIErrorAnalyzer(args.zone)
        result = analyzer.run(args.limit)
        print(f"\n‚úÖ Analyse termin√©e: {result}")
    else:
        parser.print_help()
        print("\nüí° Exemple: python ai_error_analyzer.py --zone full")


if __name__ == "__main__":
    main()
