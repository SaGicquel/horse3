#!/usr/bin/env python3
"""
SCRAPER HTML ZONE-TURF

Scrape les r√©sultats des courses depuis les pages HTML de Zone-Turf.
G√©n√®re un CSV compatible avec enrichir_zoneturf.py

Usage:
    python scraper_zoneturf_html.py --date 2024-10-20
    python scraper_zoneturf_html.py --date-range 2024-10-20 2024-10-26
"""

import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta
import csv
import argparse
from pathlib import Path
import time


class ScraperZoneTurfHTML:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update(
            {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"}
        )
        self.base_url = "https://www.zone-turf.fr"

    def get_reunions_du_jour(self, date):
        """
        R√©cup√®re la liste des r√©unions pour une date donn√©e

        Args:
            date (str): Date au format YYYY-MM-DD

        Returns:
            list: Liste des URLs de r√©unions
        """
        # Formater la date pour Zone-Turf (ex: "mardi-15-octobre-2024")
        date_obj = datetime.strptime(date, "%Y-%m-%d")
        jours = ["lundi", "mardi", "mercredi", "jeudi", "vendredi", "samedi", "dimanche"]
        mois = [
            "",
            "janvier",
            "f√©vrier",
            "mars",
            "avril",
            "mai",
            "juin",
            "juillet",
            "ao√ªt",
            "septembre",
            "octobre",
            "novembre",
            "d√©cembre",
        ]

        jour_nom = jours[date_obj.weekday()]
        mois_nom = mois[date_obj.month]

        url_date = f"{jour_nom}-{date_obj.day}-{mois_nom}-{date_obj.year}"
        url = f"{self.base_url}/resultats/resultats-pmu-du-{url_date}.html"

        print(f"üìÖ Recherche r√©unions pour {date} : {url}")

        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")

            # Chercher les liens vers les r√©unions
            reunions = []

            # Zone-Turf liste les r√©unions sous forme de liens
            # Ex: /programmes/r1-vincennes-123456.html
            links = soup.find_all("a", href=re.compile(r"/programmes/r\d+-"))

            for link in links:
                href = link.get("href")
                if href and href not in reunions:
                    reunions.append(href)

            print(f"   ‚úÖ {len(reunions)} r√©unions trouv√©es")
            return reunions

        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                print("   ‚ö†Ô∏è  Aucune r√©union pour cette date (404)")
                return []
            else:
                print(f"   ‚ùå Erreur HTTP {e.response.status_code}")
                return []
        except Exception as e:
            print(f"   ‚ùå Erreur : {e}")
            return []

    def scrape_reunion(self, reunion_url):
        """
        Scrape une r√©union compl√®te avec toutes ses courses

        Args:
            reunion_url (str): URL de la r√©union

        Returns:
            list: Liste de dictionnaires (une ligne par cheval)
        """
        print(f"   üèá Scraping r√©union : {reunion_url}")

        url = f"{self.base_url}{reunion_url}"

        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")

            # Extraire les informations de la r√©union
            # Ex: R1-VINCENNES -> reunion=1, hippodrome=VINCENNES
            match = re.search(r"r(\d+)-([a-z\-]+)", reunion_url, re.IGNORECASE)
            if not match:
                print("      ‚ùå Impossible de parser l'URL de la r√©union")
                return []

            numero_reunion = match.group(1)
            hippodrome_code = match.group(2).upper().replace("-", " ")

            # Extraire la date depuis le contenu
            # TODO: Impl√©menter extraction date r√©elle

            # Chercher toutes les courses de la r√©union
            courses_data = []

            # Zone-Turf structure: chaque course a un ID unique
            # Les r√©sultats sont dans des tableaux HTML

            # Chercher les tableaux de r√©sultats
            tables = soup.find_all("table", class_=re.compile(r"result|tableau"))

            print(f"      üìä {len(tables)} tableaux trouv√©s")

            # Pour l'instant, retourner vide (structure √† compl√©ter)
            # Cette impl√©mentation n√©cessite d'analyser plus en d√©tail la structure HTML

            return courses_data

        except Exception as e:
            print(f"      ‚ùå Erreur : {e}")
            return []

    def scrape_date(self, date):
        """
        Scrape toutes les courses d'une date

        Args:
            date (str): Date au format YYYY-MM-DD

        Returns:
            list: Liste de toutes les performances
        """
        reunions = self.get_reunions_du_jour(date)

        all_data = []
        for reunion_url in reunions:
            data = self.scrape_reunion(reunion_url)
            all_data.extend(data)
            time.sleep(0.5)  # Pause pour ne pas surcharger le serveur

        return all_data

    def save_to_csv(self, data, output_file):
        """
        Sauvegarde les donn√©es au format CSV compatible avec enrichir_zoneturf.py

        Args:
            data (list): Liste de dictionnaires
            output_file (str): Chemin du fichier CSV de sortie
        """
        if not data:
            print("   ‚ö†Ô∏è  Aucune donn√©e √† sauvegarder")
            return

        # Format attendu par enrichir_zoneturf.py :
        # Date;Hippodrome;Reunion;Course;Num;Cheval;Musique;Corde;Ecart;Temps;CoteDirect;CoteRef

        fieldnames = [
            "Date",
            "Hippodrome",
            "Reunion",
            "Course",
            "Num",
            "Cheval",
            "Musique",
            "Corde",
            "Ecart",
            "Temps",
            "CoteDirect",
            "CoteRef",
        ]

        with open(output_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter=";")
            writer.writeheader()
            writer.writerows(data)

        print(f"   ‚úÖ {len(data)} lignes sauvegard√©es dans {output_file}")


def main():
    parser = argparse.ArgumentParser(description="Scraper HTML Zone-Turf")
    parser.add_argument("--date", type=str, help="Date √† scraper (YYYY-MM-DD)")
    parser.add_argument(
        "--date-range",
        nargs=2,
        metavar=("START", "END"),
        help="Plage de dates (YYYY-MM-DD YYYY-MM-DD)",
    )
    parser.add_argument(
        "--output-dir", type=str, default="data/zoneturf", help="R√©pertoire de sortie pour les CSV"
    )

    args = parser.parse_args()

    # Cr√©er le r√©pertoire de sortie
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    scraper = ScraperZoneTurfHTML()

    # D√©terminer les dates √† scraper
    if args.date:
        dates = [args.date]
    elif args.date_range:
        start = datetime.strptime(args.date_range[0], "%Y-%m-%d")
        end = datetime.strptime(args.date_range[1], "%Y-%m-%d")
        dates = []
        current = start
        while current <= end:
            dates.append(current.strftime("%Y-%m-%d"))
            current += timedelta(days=1)
    else:
        # Par d√©faut : hier
        hier = datetime.now() - timedelta(days=1)
        dates = [hier.strftime("%Y-%m-%d")]

    print("\n" + "=" * 70)
    print("üèá SCRAPER HTML ZONE-TURF")
    print("=" * 70)
    print(f"üìÖ Dates : {dates[0]}" + (f" ‚Üí {dates[-1]}" if len(dates) > 1 else ""))
    print()

    # Scraper chaque date
    for date in dates:
        print("=" * 70)
        print(f"üìÜ {date}")
        print("=" * 70)

        data = scraper.scrape_date(date)

        if data:
            output_file = output_dir / f"zoneturf_{date.replace('-', '')}.csv"
            scraper.save_to_csv(data, str(output_file))
        else:
            print("   ‚ö†Ô∏è  Aucune donn√©e r√©cup√©r√©e pour cette date")

        print()

    print("=" * 70)
    print("‚úÖ Scraping termin√© !")
    print("=" * 70)


if __name__ == "__main__":
    main()
