#!/bin/bash

################################################################################
# SCRAPING HISTORIQUE EN CONTINU
################################################################################
#
# Ce script lance le scraping en boucle continue jusqu'√† compl√©tion
# D√®s qu'une session de 10 p√©riodes est termin√©e, une nouvelle d√©marre
#
# Usage:
#   ./scraper_continu.sh              # Lance en avant-plan
#   ./scraper_continu.sh &            # Lance en arri√®re-plan
#   nohup ./scraper_continu.sh &      # Lance et persiste apr√®s fermeture terminal
#
# Pour arr√™ter:
#   touch /Users/gicquelsacha/horse3/STOP_SCRAPING
#   ou kill le processus
#
################################################################################

PROJECT_DIR="/Users/gicquelsacha/horse3"
VENV_DIR="$PROJECT_DIR/.venv"
PYTHON="$VENV_DIR/bin/python"
LOG_DIR="$PROJECT_DIR/logs"
STOP_FILE="$PROJECT_DIR/STOP_SCRAPING"

# Nombre de p√©riodes par session (10 p√©riodes = 30 jours)
PERIODS=10

# Pause entre sessions (secondes) - pour √©viter surcharge API
PAUSE_BETWEEN=30

# Cr√©er dossier logs
mkdir -p "$LOG_DIR"

# Supprimer fichier stop s'il existe
rm -f "$STOP_FILE"

echo "============================================================"
echo "üöÄ SCRAPING CONTINU D√âMARR√â"
echo "============================================================"
echo "   P√©riodes par session: $PERIODS ($(($PERIODS * 3)) jours)"
echo "   Pause entre sessions: ${PAUSE_BETWEEN}s"
echo "   Pour arr√™ter: touch $STOP_FILE"
echo "   Logs: $LOG_DIR/continu_*.log"
echo "============================================================"
echo ""

SESSION=1

while true; do
    # V√©rifier si on doit s'arr√™ter
    if [ -f "$STOP_FILE" ]; then
        echo ""
        echo "üõë Fichier STOP d√©tect√© - Arr√™t du scraping continu"
        rm -f "$STOP_FILE"
        break
    fi

    # V√©rifier le statut actuel
    STATUS=$($PYTHON "$PROJECT_DIR/scraper_historique_auto.py" --status 2>/dev/null | grep "status:" | awk '{print $2}')

    if [ "$STATUS" = "completed" ]; then
        echo ""
        echo "üéâ SCRAPING HISTORIQUE TERMIN√â !"
        echo "   Toutes les donn√©es sur 5 ans ont √©t√© r√©cup√©r√©es."
        break
    fi

    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    LOG_FILE="$LOG_DIR/continu_${TIMESTAMP}.log"

    echo ""
    echo "============================================================"
    echo "üì¶ SESSION $SESSION - $(date '+%Y-%m-%d %H:%M:%S')"
    echo "============================================================"

    # Afficher progression avant
    echo "üìä Progression avant session:"
    $PYTHON "$PROJECT_DIR/scraper_historique_auto.py" --status 2>/dev/null | grep -E "(progress_percent|remaining_days|last_scraped)"

    echo ""
    echo "üîÑ Lancement de $PERIODS p√©riodes..."

    # Lancer le scraping
    $PYTHON "$PROJECT_DIR/scraper_historique_auto.py" --periods $PERIODS 2>&1 | tee "$LOG_FILE"

    EXIT_CODE=$?

    if [ $EXIT_CODE -ne 0 ]; then
        echo "‚ö†Ô∏è  Erreur d√©tect√©e (code $EXIT_CODE), pause de 60s avant retry..."
        sleep 60
    else
        echo "‚úÖ Session $SESSION termin√©e avec succ√®s"
    fi

    # Afficher progression apr√®s
    echo ""
    echo "üìä Progression apr√®s session:"
    $PYTHON "$PROJECT_DIR/scraper_historique_auto.py" --status 2>/dev/null | grep -E "(progress_percent|remaining_days|last_scraped)"

    SESSION=$((SESSION + 1))

    # Petite pause pour ne pas surcharger l'API
    echo ""
    echo "‚è≥ Pause de ${PAUSE_BETWEEN}s avant prochaine session..."
    sleep $PAUSE_BETWEEN
done

echo ""
echo "============================================================"
echo "üèÅ SCRAPING CONTINU TERMIN√â"
echo "   Sessions effectu√©es: $((SESSION - 1))"
echo "   Date fin: $(date '+%Y-%m-%d %H:%M:%S')"
echo "============================================================"
