#!/usr/bin/env python3
"""
Extraction COMPLETE et SÃ‰CURISÃ‰E de toutes les donnÃ©es 2020-2025
Traitement par trÃ¨s petits chunks pour Ã©viter tout crash
"""

import sys
import os
import time
import psycopg2
import csv
from datetime import datetime

# Configuration de la base de donnÃ©es
DB_CONFIG = {
    "host": "localhost",
    "port": 54624,
    "database": "pmu_database",
    "user": "pmu_user",
    "password": "pmu_secure_password_2025",
}


def extract_all_data_safe():
    """
    Extraction de TOUTES les donnÃ©es 2020-2025 par trÃ¨s petits chunks
    Ultra-sÃ©curisÃ© pour Ã©viter tout crash du terminal
    """

    print("ðŸš€ DÃ©but de l'extraction COMPLÃˆTE des donnÃ©es 2020-2025")
    print("âš¡ MÃ©thode ultra-sÃ©curisÃ©e par petits chunks")

    output_file = "data/ml_features_COMPLETE_2020_2025.csv"

    # Connexion Ã  la base
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        print("âœ… Connexion Ã  la base de donnÃ©es rÃ©ussie")
    except Exception as e:
        print(f"âŒ Erreur de connexion: {e}")
        return

    # 1. Compter le total disponible
    print("ðŸ“Š Comptage des donnÃ©es disponibles...")
    cursor.execute("""
        SELECT COUNT(*)
        FROM cheval_courses_seen
        WHERE annee >= 2020
        AND annee <= 2025
        AND place_finale IS NOT NULL
    """)
    total_count = cursor.fetchone()[0]
    print(f"ðŸ“ˆ TOTAL Ã  extraire: {total_count:,} performances")

    # 2. Extraction par chunks de 2000 lignes (trÃ¨s petit pour sÃ©curitÃ©)
    chunk_size = 2000
    offset = 0
    chunk_num = 0

    # CrÃ©er le fichier CSV
    with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
        writer = None

        while offset < total_count:
            chunk_num += 1

            print(f"ðŸ”„ Chunk {chunk_num} - Offset: {offset:,} ({offset/total_count*100:.1f}%)")

            # RequÃªte pour ce chunk
            cursor.execute(
                """
                SELECT
                    row_number() OVER (ORDER BY annee, race_key) as id_performance,
                    race_key as id_course,
                    nom_norm,
                    annee,
                    place_finale as position_arrivee,
                    CASE WHEN place_finale = 1 THEN 1 ELSE 0 END as victoire,
                    CASE WHEN place_finale <= 3 THEN 1 ELSE 0 END as place,
                    numero_dossard as numero_corde,
                    cote_finale as cote_sp,
                    distance_m as distance,
                    discipline,
                    nombre_partants,
                    hippodrome_nom,
                    driver_jockey,
                    entraineur,
                    race_key as date_course,
                    sexe,
                    age
                FROM cheval_courses_seen
                WHERE annee >= 2020
                AND annee <= 2025
                AND place_finale IS NOT NULL
                ORDER BY annee, race_key
                LIMIT %s OFFSET %s
            """,
                (chunk_size, offset),
            )

            rows = cursor.fetchall()

            if not rows:
                print("âœ… Fin des donnÃ©es")
                break

            # Ã‰crire le header au premier chunk
            if writer is None:
                fieldnames = [
                    "id_performance",
                    "id_course",
                    "nom_norm",
                    "annee",
                    "position_arrivee",
                    "victoire",
                    "place",
                    "numero_corde",
                    "cote_sp",
                    "distance",
                    "discipline",
                    "nombre_partants",
                    "hippodrome_nom",
                    "driver_jockey",
                    "entraineur",
                    "date_course",
                    "sexe",
                    "age",
                ]
                writer = csv.writer(csvfile)
                writer.writerow(fieldnames)
                print("ðŸ“ Header CSV crÃ©Ã©")

            # Ã‰crire les donnÃ©es
            for row in rows:
                writer.writerow(row)

            offset += len(rows)

            print(f"âœ… Chunk {chunk_num} terminÃ©: {len(rows)} lignes - Total: {offset:,}")

            # Pause sÃ©curitÃ© entre les chunks
            time.sleep(0.1)

            # Commit pÃ©riodique pour libÃ©rer la mÃ©moire
            if chunk_num % 10 == 0:
                csvfile.flush()
                print(f"ðŸ’¾ Flush fichier - Progression: {offset/total_count*100:.1f}%")

    # Fermeture propre
    cursor.close()
    conn.close()

    print("ðŸŽ‰ EXTRACTION COMPLÃˆTE TERMINÃ‰E !")
    print(f"ðŸ“„ Fichier crÃ©Ã©: {output_file}")
    print(f"ðŸ“Š Total extrait: {offset:,} performances")

    # VÃ©rification finale
    print("ðŸ” VÃ©rification finale du fichier...")
    try:
        with open(output_file, "r") as f:
            line_count = sum(1 for _ in f) - 1  # -1 pour le header
        print(f"âœ… VÃ©rification OK: {line_count:,} lignes dans le fichier")
    except Exception as e:
        print(f"âš ï¸  Erreur de vÃ©rification: {e}")


if __name__ == "__main__":
    extract_all_data_safe()
