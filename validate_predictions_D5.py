#!/usr/bin/env python3
"""
VALIDATION DES PRÃ‰DICTIONS PHASE D5
==================================

Valide et analyse les prÃ©dictions gÃ©nÃ©rÃ©es par XGBoost SAFE
sur tout l'historique.
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime

# Configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def validate_predictions():
    """Valide et analyse les prÃ©dictions gÃ©nÃ©rÃ©es"""
    
    logger.info("ğŸ” VALIDATION DES PRÃ‰DICTIONS D5")
    logger.info("=" * 70)
    
    # Chargement des prÃ©dictions
    logger.info("ğŸ“‚ Chargement du fichier de prÃ©dictions...")
    df = pd.read_csv('data/backtest_predictions.csv')
    
    logger.info(f"âœ… PrÃ©dictions chargÃ©es: {len(df):,} lignes Ã— {df.shape[1]} colonnes")
    
    # 1. VALIDATION DE LA STRUCTURE
    logger.info("\nğŸ“‹ VALIDATION STRUCTURE:")
    print("-" * 50)
    
    # Colonnes attendues
    expected_cols = ['race_key', 'id_cheval', 'date_course', 'p_model_win', 
                    'is_win', 'place', 'cote_sp', 'split', 'position_arrivee']
    
    missing_cols = [col for col in expected_cols if col not in df.columns]
    extra_cols = [col for col in df.columns if col not in expected_cols + ['cote_pm']]
    
    if missing_cols:
        print(f"âŒ Colonnes manquantes: {missing_cols}")
    else:
        print("âœ… Toutes les colonnes attendues prÃ©sentes")
    
    if extra_cols:
        print(f"â„¹ï¸  Colonnes supplÃ©mentaires: {extra_cols}")
    
    print(f"ğŸ“Š Colonnes disponibles: {list(df.columns)}")
    
    # 2. VALIDATION TEMPORELLE
    logger.info("\nğŸ“… VALIDATION TEMPORELLE:")
    print("-" * 50)
    
    df['date_course'] = pd.to_datetime(df['date_course'])
    date_min = df['date_course'].min()
    date_max = df['date_course'].max()
    
    print(f"ğŸ“… PÃ©riode couverte: {date_min.strftime('%Y-%m-%d')} Ã  {date_max.strftime('%Y-%m-%d')}")
    
    # Distribution par annÃ©e
    df['annee'] = df['date_course'].dt.year
    yearly_dist = df['annee'].value_counts().sort_index()
    
    print(f"\nğŸ“Š RÃ‰PARTITION ANNUELLE:")
    total = len(df)
    for year, count in yearly_dist.items():
        pct = (count / total) * 100
        print(f"   {year}: {count:,} ({pct:.1f}%)")
    
    # 3. VALIDATION DES SPLITS
    logger.info("\nğŸ¯ VALIDATION SPLITS:")
    print("-" * 50)
    
    split_dist = df['split'].value_counts()
    
    for split_name, count in split_dist.items():
        pct = (count / total) * 100
        print(f"ğŸ“Š {split_name.upper()}: {count:,} ({pct:.1f}%)")
    
    # VÃ©rification cohÃ©rence temporelle des splits
    split_years = df.groupby('split')['annee'].agg(['min', 'max'])
    print(f"\nğŸ” COHÃ‰RENCE TEMPORELLE DES SPLITS:")
    for split_name, row in split_years.iterrows():
        print(f"   {split_name.upper()}: {row['min']}-{row['max']}")
    
    # 4. VALIDATION DES PRÃ‰DICTIONS
    logger.info("\nğŸ¯ VALIDATION PRÃ‰DICTIONS:")
    print("-" * 50)
    
    # Statistiques des probabilitÃ©s
    pred_stats = df['p_model_win'].describe()
    print(f"ğŸ“ˆ STATISTIQUES p_model_win:")
    print(f"   Min: {pred_stats['min']:.6f}")
    print(f"   25%: {pred_stats['25%']:.4f}")
    print(f"   MÃ©diane: {pred_stats['50%']:.4f}")
    print(f"   75%: {pred_stats['75%']:.4f}")
    print(f"   Max: {pred_stats['max']:.6f}")
    print(f"   Moyenne: {pred_stats['mean']:.4f}")
    print(f"   Ã‰cart-type: {pred_stats['std']:.4f}")
    
    # Validation des bornes
    valid_probs = (df['p_model_win'] >= 0) & (df['p_model_win'] <= 1)
    invalid_count = (~valid_probs).sum()
    
    if invalid_count > 0:
        print(f"âŒ ProbabilitÃ©s invalides (hors [0,1]): {invalid_count}")
    else:
        print("âœ… Toutes les probabilitÃ©s dans [0,1]")
    
    # Valeurs nulles
    null_preds = df['p_model_win'].isnull().sum()
    if null_preds > 0:
        print(f"âš ï¸  PrÃ©dictions nulles: {null_preds}")
    else:
        print("âœ… Aucune prÃ©diction nulle")
    
    # 5. VALIDATION DES TARGETS
    logger.info("\nğŸ† VALIDATION TARGETS:")
    print("-" * 50)
    
    # Victoires
    total_wins = df['is_win'].sum()
    win_rate = (total_wins / len(df)) * 100
    print(f"ğŸ† Victoires totales: {total_wins:,} ({win_rate:.1f}%)")
    
    # Places
    total_places = df['place'].sum()
    place_rate = (total_places / len(df)) * 100
    print(f"ğŸ¥‰ Places totales: {total_places:,} ({place_rate:.1f}%)")
    
    # CohÃ©rence victoire/position
    win_pos_1 = ((df['is_win'] == 1) & (df['position_arrivee'] == 1)).sum()
    total_pos_1 = (df['position_arrivee'] == 1).sum()
    
    print(f"ğŸ” Victoires en position 1: {win_pos_1:,}")
    print(f"ğŸ” Total positions 1: {total_pos_1:,}")
    
    if win_pos_1 == total_pos_1:
        print("âœ… CohÃ©rence victoire/position validÃ©e")
    else:
        print(f"âŒ IncohÃ©rence victoire/position: {total_pos_1 - win_pos_1} Ã©cart")
    
    # 6. VALIDATION DES COTES
    logger.info("\nğŸ’° VALIDATION COTES:")
    print("-" * 50)
    
    cote_stats = df['cote_sp'].describe()
    cotes_disponibles = (~df['cote_sp'].isnull()).sum()
    cote_coverage = (cotes_disponibles / len(df)) * 100
    
    print(f"ğŸ“Š Cotes disponibles: {cotes_disponibles:,} ({cote_coverage:.1f}%)")
    print(f"ğŸ“ˆ Cote min: {cote_stats['min']:.1f}")
    print(f"ğŸ“ˆ Cote mÃ©diane: {cote_stats['50%']:.1f}")
    print(f"ğŸ“ˆ Cote max: {cote_stats['max']:.1f}")
    
    # 7. ANALYSE DE PERFORMANCE PAR SPLIT
    logger.info("\nğŸ“Š PERFORMANCE PAR SPLIT:")
    print("-" * 50)
    
    from sklearn.metrics import roc_auc_score
    
    for split_name in ['train', 'val', 'test']:
        split_data = df[df['split'] == split_name]
        if len(split_data) > 0:
            try:
                auc = roc_auc_score(split_data['is_win'], split_data['p_model_win'])
                win_rate = split_data['is_win'].mean() * 100
                avg_prob = split_data['p_model_win'].mean()
                
                print(f"ğŸ“Š {split_name.upper()}:")
                print(f"   ğŸ¯ AUC: {auc:.4f}")
                print(f"   ğŸ† Taux victoire: {win_rate:.1f}%")
                print(f"   ğŸ“ˆ Prob. moyenne: {avg_prob:.4f}")
                
            except Exception as e:
                print(f"âŒ Erreur calcul AUC pour {split_name}: {e}")
    
    # 8. Ã‰CHANTILLONS REPRÃ‰SENTATIFS
    logger.info("\nğŸ” Ã‰CHANTILLONS REPRÃ‰SENTATIFS:")
    print("-" * 50)
    
    # Top prÃ©dictions (favoris du modÃ¨le)
    top_preds = df.nlargest(5, 'p_model_win')[['race_key', 'id_cheval', 'date_course', 
                                                'p_model_win', 'is_win', 'cote_sp']]
    print("ğŸ† TOP 5 PRÃ‰DICTIONS:")
    for _, row in top_preds.iterrows():
        result = "âœ… GAGNÃ‰" if row['is_win'] == 1 else "âŒ PERDU"
        print(f"   {row['date_course']} - {row['id_cheval']}: {row['p_model_win']:.4f} - Cote {row['cote_sp']:.1f} - {result}")
    
    # PrÃ©dictions rÃ©centes
    recent = df[df['date_course'] >= '2025-12-01'].head(5)[['race_key', 'id_cheval', 'date_course', 
                                                           'p_model_win', 'is_win', 'cote_sp']]
    if len(recent) > 0:
        print("\nğŸ“… Ã‰CHANTILLON RÃ‰CENT:")
        for _, row in recent.iterrows():
            result = "âœ… GAGNÃ‰" if row['is_win'] == 1 else "âŒ PERDU" 
            print(f"   {row['date_course']} - {row['id_cheval']}: {row['p_model_win']:.4f} - Cote {row['cote_sp']:.1f} - {result}")
    
    # 9. RÃ‰SUMÃ‰ FINAL
    logger.info("\nğŸ“ RÃ‰SUMÃ‰ VALIDATION D5:")
    print("=" * 70)
    
    validation_score = 0
    max_score = 8
    
    # CritÃ¨res de validation
    if len(df) > 600000:
        validation_score += 1
        print("âœ… [1/8] Volume de donnÃ©es suffisant (>600K)")
    else:
        print(f"âŒ [0/8] Volume insuffisant ({len(df):,} < 600K)")
    
    if not missing_cols:
        validation_score += 1
        print("âœ… [1/8] Structure complÃ¨te")
    else:
        print("âŒ [0/8] Structure incomplÃ¨te")
    
    if (date_max - date_min).days > 1500:  # ~4+ annÃ©es
        validation_score += 1
        print("âœ… [1/8] PÃ©riode historique Ã©tendue")
    else:
        print("âŒ [0/8] PÃ©riode historique insuffisante")
    
    if len(split_dist) == 3:
        validation_score += 1
        print("âœ… [1/8] Splits train/val/test prÃ©sents")
    else:
        print("âŒ [0/8] Splits incomplets")
    
    if invalid_count == 0:
        validation_score += 1
        print("âœ… [1/8] ProbabilitÃ©s valides")
    else:
        print("âŒ [0/8] ProbabilitÃ©s invalides")
    
    if win_pos_1 == total_pos_1:
        validation_score += 1
        print("âœ… [1/8] CohÃ©rence targets")
    else:
        print("âŒ [0/8] IncohÃ©rence targets")
    
    if 8 <= win_rate <= 12:  # Taux de victoire rÃ©aliste hippisme
        validation_score += 1
        print("âœ… [1/8] Taux de victoire rÃ©aliste")
    else:
        print("âŒ [0/8] Taux de victoire anormal")
    
    if cote_coverage > 80:
        validation_score += 1
        print("âœ… [1/8] Couverture cotes suffisante")
    else:
        print("âŒ [0/8] Couverture cotes insuffisante")
    
    print(f"\nğŸ† SCORE VALIDATION: {validation_score}/{max_score}")
    
    if validation_score >= 7:
        print("ğŸŸ¢ PRÃ‰DICTIONS VALIDÃ‰ES - PrÃªtes pour backtesting!")
    elif validation_score >= 5:
        print("ğŸŸ¡ PRÃ‰DICTIONS PARTIELLEMENT VALIDÃ‰ES - VÃ©rifications recommandÃ©es")
    else:
        print("ğŸ”´ PRÃ‰DICTIONS NON VALIDÃ‰ES - Corrections nÃ©cessaires")
    
    return {
        'total_predictions': len(df),
        'date_range': f"{date_min.strftime('%Y-%m-%d')} Ã  {date_max.strftime('%Y-%m-%d')}",
        'validation_score': validation_score,
        'max_score': max_score,
        'win_rate': win_rate,
        'splits': dict(split_dist)
    }

if __name__ == "__main__":
    validate_predictions()