#!/usr/bin/env python3
"""
SPLIT TRAIN/VAL/TEST DU DATASET SAFE
===================================

Division temporelle du dataset SAFE en ensembles d'entraÃ®nement,
validation et test pour Ã©viter le data leakage temporel.
"""

import pandas as pd
import numpy as np
from datetime import datetime
import logging

# Configuration des logs
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def split_dataset_safe():
    """Divise le dataset SAFE en train/val/test de maniÃ¨re temporelle"""
    
    logging.info("ğŸ”„ DÃ‰MARRAGE SPLIT TRAIN/VAL/TEST DATASET SAFE")
    logging.info("=" * 70)
    
    try:
        # Chargement du dataset SAFE
        logging.info("ğŸ“‚ Chargement dataset SAFE...")
        df = pd.read_csv('data/ml_features_SAFE.csv')
        
        logging.info(f"âœ… Dataset chargÃ©: {df.shape[0]:,} lignes Ã— {df.shape[1]} colonnes")
        
        # Conversion de la date
        logging.info("ğŸ“… Analyse des dates...")
        # Extraction de la date depuis l'ID de course (format: YYYY-MM-DD|R1|C1|VIN)
        df['date_extracted'] = df['date_course'].str.split('|').str[0]
        df['date_course'] = pd.to_datetime(df['date_extracted'])
        
        # Statistiques temporelles
        date_min = df['date_course'].min()
        date_max = df['date_course'].max()
        nb_annees = (date_max - date_min).days / 365.25
        
        logging.info(f"ğŸ“Š PÃ©riode couverte: {date_min.strftime('%Y-%m-%d')} Ã  {date_max.strftime('%Y-%m-%d')}")
        logging.info(f"ğŸ“Š DurÃ©e: {nb_annees:.1f} annÃ©es")
        
        # Distribution par annÃ©e
        df['annee'] = df['date_course'].dt.year
        repartition_annuelle = df['annee'].value_counts().sort_index()
        
        logging.info("\nğŸ“ˆ RÃ‰PARTITION ANNUELLE:")
        for annee, count in repartition_annuelle.items():
            pct = (count / len(df)) * 100
            logging.info(f"   {annee}: {count:,} courses ({pct:.1f}%)")
        
        # StratÃ©gie de split temporel
        # Train: 2020-2022 (3 annÃ©es complÃ¨tes)
        # Validation: 2023 (1 annÃ©e)
        # Test: 2024-2025 (donnÃ©es rÃ©centes)
        
        logging.info("\nğŸ¯ STRATÃ‰GIE DE SPLIT TEMPOREL:")
        logging.info("   ğŸ“š Train: 2020-2022 (3 annÃ©es)")
        logging.info("   ğŸ” Validation: 2023 (1 annÃ©e)")
        logging.info("   ğŸ§ª Test: 2024-2025 (donnÃ©es rÃ©centes)")
        
        # CrÃ©ation des masques
        mask_train = (df['annee'] >= 2020) & (df['annee'] <= 2022)
        mask_val = (df['annee'] == 2023)
        mask_test = (df['annee'] >= 2024)
        
        # Extraction des ensembles
        df_train = df[mask_train].copy()
        df_val = df[mask_val].copy()
        df_test = df[mask_test].copy()
        
        # Statistiques des splits
        logging.info(f"\nğŸ“Š RÃ‰SULTATS DU SPLIT:")
        logging.info(f"   ğŸ“š Train: {len(df_train):,} lignes ({len(df_train)/len(df)*100:.1f}%)")
        logging.info(f"   ğŸ” Val: {len(df_val):,} lignes ({len(df_val)/len(df)*100:.1f}%)")
        logging.info(f"   ğŸ§ª Test: {len(df_test):,} lignes ({len(df_test)/len(df)*100:.1f}%)")
        logging.info(f"   ğŸ“Š Total: {len(df_train) + len(df_val) + len(df_test):,} lignes")
        
        # VÃ©rification de la cohÃ©rence
        assert len(df_train) + len(df_val) + len(df_test) == len(df), "Perte de donnÃ©es dans le split!"
        
        # Distribution des targets dans chaque ensemble
        logging.info(f"\nğŸ¯ DISTRIBUTION DES TARGETS:")
        
        for dataset_name, dataset in [('TRAIN', df_train), ('VAL', df_val), ('TEST', df_test)]:
            victoires_pct = (dataset['victoire'].sum() / len(dataset)) * 100
            places_pct = (dataset['place'].sum() / len(dataset)) * 100
            
            logging.info(f"   {dataset_name}:")
            logging.info(f"      ğŸ† Victoires: {dataset['victoire'].sum():,} ({victoires_pct:.1f}%)")
            logging.info(f"      ğŸ¥‰ Places: {dataset['place'].sum():,} ({places_pct:.1f}%)")
        
        # Sauvegarde des ensembles
        logging.info(f"\nğŸ’¾ SAUVEGARDE DES ENSEMBLES:")
        
        # Suppression des colonnes temporaires
        for df_temp in [df_train, df_val, df_test]:
            for col in ['annee', 'date_extracted']:
                if col in df_temp.columns:
                    df_temp.drop(col, axis=1, inplace=True)
        
        # Sauvegarde
        df_train.to_csv('data/train_SAFE.csv', index=False)
        logging.info(f"   âœ… Train sauvÃ©: data/train_SAFE.csv")
        
        df_val.to_csv('data/val_SAFE.csv', index=False)
        logging.info(f"   âœ… Validation sauvÃ©: data/val_SAFE.csv")
        
        df_test.to_csv('data/test_SAFE.csv', index=False)
        logging.info(f"   âœ… Test sauvÃ©: data/test_SAFE.csv")
        
        # RÃ©sumÃ© final
        logging.info(f"\nğŸ“‹ RÃ‰SUMÃ‰ FINAL:")
        logging.info(f"   ğŸ“‚ Fichiers gÃ©nÃ©rÃ©s: 3 datasets")
        logging.info(f"   ğŸ“Š Colonnes par dataset: {df_train.shape[1]}")
        logging.info(f"   ğŸ¯ Targets disponibles: position_arrivee, victoire, place")
        logging.info(f"   ğŸ“… Split temporel: Garantie anti-leakage")
        
        return {
            'train_size': len(df_train),
            'val_size': len(df_val),
            'test_size': len(df_test),
            'nb_features': df_train.shape[1] - 3,  # -3 pour les targets
            'periode_train': '2020-2022',
            'periode_val': '2023',
            'periode_test': '2024-2025'
        }
        
    except Exception as e:
        logging.error(f"âŒ Erreur lors du split: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    split_dataset_safe()