"""
ğŸ”„ Pipeline de Retraining Automatique - Phase 8 Online Learning
================================================================

Script pour retrainer automatiquement le modÃ¨le avec les nouveaux feedbacks.

Workflow:
1. Charger donnÃ©es originales d'entraÃ®nement
2. RÃ©cupÃ©rer feedbacks des N derniers jours
3. Merger feedbacks avec donnÃ©es originales
4. Retrainer Stacking Ensemble
5. Valider performance (ROC-AUC > seuil)
6. Sauvegarder nouveau modÃ¨le si validation OK
7. Archiver ancien modÃ¨le

Usage:
    python train_online.py --days 30 --min-roc-auc 0.70
    python train_online.py --dry-run  # Test sans sauvegarder

Scheduling:
    # Cron (chaque lundi Ã  3h du matin)
    0 3 * * 1 cd /path/to/horse3 && python train_online.py --days 7 >> logs/retraining.log 2>&1

Auteur: Phase 8 - Online Learning
Date: 2025-11-14
"""

import os
import sys
import json
import pickle
import shutil
import logging
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, Tuple, Optional

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score
import xgboost as xgb
import lightgbm as lgb

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("logs/retraining.log"), logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)


class OnlineTrainer:
    """Gestionnaire du retraining automatique."""

    def __init__(
        self,
        days: int = 7,
        min_roc_auc: float = 0.70,
        min_new_samples: int = 100,
        dry_run: bool = False,
    ):
        """
        Initialise le trainer.

        Args:
            days: Nombre de jours de feedback Ã  inclure
            min_roc_auc: ROC-AUC minimum pour valider nouveau modÃ¨le
            min_new_samples: Nombre minimum de nouveaux Ã©chantillons requis
            dry_run: Si True, ne sauvegarde pas le modÃ¨le
        """
        self.days = days
        self.min_roc_auc = min_roc_auc
        self.min_new_samples = min_new_samples
        self.dry_run = dry_run

        # Chemins
        self.data_dir = Path("data")
        self.models_dir = Path("data/models")
        self.champion_dir = self.models_dir / "champion"
        self.challenger_dir = self.models_dir / "challenger"
        self.archive_dir = self.models_dir / "archive"

        # Features (62 features comme modÃ¨le original)
        self.feature_columns = [
            # Forme rÃ©cente (7)
            "forme_5c",
            "forme_10c",
            "nb_courses_12m",
            "nb_victoires_12m",
            "nb_places_12m",
            "derniere_place",
            "derniere_victoire",
            # Aptitude (3)
            "aptitude_distance",
            "aptitude_piste",
            "aptitude_hippodrome",
            # Jockey/Entraineur (6)
            "taux_victoires_jockey",
            "taux_places_jockey",
            "taux_victoires_entraineur",
            "taux_places_entraineur",
            "synergie_jockey_cheval",
            "synergie_entraineur_cheval",
            # Course (3)
            "distance_norm",
            "niveau_moyen_concurrent",
            "nb_partants",
            # MarchÃ© (5)
            "cote_turfbzh",
            "rang_cote_turfbzh",
            "cote_sp",
            "rang_cote_sp",
            "prediction_ia_gagnant",
            "elo_cheval",
            "ecart_cote_ia",
        ]

        self.metadata = {}

    def load_original_training_data(self) -> pd.DataFrame:
        """Charge les donnÃ©es d'entraÃ®nement originales."""
        logger.info("=" * 80)
        logger.info("ğŸ“¦ CHARGEMENT DONNÃ‰ES ORIGINALES")
        logger.info("=" * 80)

        # Chercher fichier features
        feature_files = [
            self.data_dir / "ml_features_complete.csv",
            self.data_dir / "ml_features.csv",
            self.data_dir / "normalized" / "X_train.parquet",
        ]

        for filepath in feature_files:
            if filepath.exists():
                logger.info(f"ğŸ“‚ Fichier trouvÃ©: {filepath}")

                if filepath.suffix == ".parquet":
                    df = pd.read_parquet(filepath)
                else:
                    df = pd.read_csv(filepath)

                logger.info(f"   âœ… {len(df):,} lignes chargÃ©es")
                return df

        raise FileNotFoundError("âŒ Aucun fichier de features trouvÃ©")

    def load_feedback_data(self) -> pd.DataFrame:
        """
        Charge les feedbacks des N derniers jours.

        En production: requÃªte PostgreSQL sur table feedback_results.
        En dÃ©veloppement: stub avec donnÃ©es simulÃ©es.
        """
        logger.info("=" * 80)
        logger.info(f"ğŸ“¥ CHARGEMENT FEEDBACK ({self.days} derniers jours)")
        logger.info("=" * 80)

        # TODO: Remplacer par vraie requÃªte PostgreSQL
        # SELECT * FROM feedback_results
        # WHERE timestamp_feedback >= NOW() - INTERVAL '{self.days} days'

        # Stub: donnÃ©es simulÃ©es pour dÃ©veloppement
        logger.warning("âš ï¸  Mode STUB: utilisation donnÃ©es simulÃ©es (pas de PostgreSQL)")

        # CrÃ©er DataFrame vide avec bonnes colonnes
        feedback_df = pd.DataFrame(columns=["course_id", "cheval_id", "position_arrivee"])

        logger.info(f"   â„¹ï¸  {len(feedback_df):,} feedbacks trouvÃ©s")

        if len(feedback_df) < self.min_new_samples:
            logger.warning(
                f"âš ï¸  Seulement {len(feedback_df)} feedbacks (min: {self.min_new_samples})"
            )
            logger.warning("   Retraining annulÃ©: pas assez de nouvelles donnÃ©es")
            return None

        return feedback_df

    def merge_data(self, original_df: pd.DataFrame, feedback_df: pd.DataFrame) -> pd.DataFrame:
        """Merge donnÃ©es originales et feedbacks."""
        logger.info("=" * 80)
        logger.info("ğŸ”— MERGE DONNÃ‰ES")
        logger.info("=" * 80)

        if feedback_df is None or len(feedback_df) == 0:
            logger.info("   â„¹ï¸  Pas de feedback, utilisation donnÃ©es originales uniquement")
            return original_df

        # TODO: ImplÃ©menter vraie logique de merge
        # 1. Convertir feedback en format features
        # 2. Append Ã  original_df
        # 3. DÃ©dupliquer si nÃ©cessaire

        logger.info(f"   âœ… {len(original_df):,} lignes originales")
        logger.info(f"   âœ… {len(feedback_df):,} nouveaux feedbacks")

        merged_df = original_df.copy()  # Stub

        logger.info(f"   ğŸ“Š Total: {len(merged_df):,} lignes")

        return merged_df

    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """PrÃ©pare X et y pour entraÃ®nement."""
        logger.info("=" * 80)
        logger.info("ğŸ”§ PRÃ‰PARATION FEATURES")
        logger.info("=" * 80)

        # Filtrer colonnes features disponibles
        available_features = [col for col in self.feature_columns if col in df.columns]
        missing_features = set(self.feature_columns) - set(available_features)

        if missing_features:
            logger.warning(f"âš ï¸  {len(missing_features)} features manquantes: {missing_features}")

        logger.info(f"   âœ… {len(available_features)} features disponibles")

        # Extraire X et y
        X = df[available_features].copy()
        y = df["victoire"].copy()

        # Remplacer NaN par 0
        X = X.fillna(0)

        logger.info(f"   ğŸ“Š X: {X.shape}")
        logger.info(f"   ğŸ¯ y: {y.shape} ({y.sum()} victoires, {100*y.mean():.1f}%)")

        return X, y

    def build_stacking_model(self) -> StackingClassifier:
        """Construit le modÃ¨le Stacking Ensemble (mÃªme architecture que Phase 6)."""
        logger.info("=" * 80)
        logger.info("ğŸ—ï¸  CONSTRUCTION MODÃˆLE STACKING")
        logger.info("=" * 80)

        # Base learners (hyperparams optimisÃ©s Phase 6)
        rf = RandomForestClassifier(
            n_estimators=200,
            max_depth=20,
            min_samples_split=10,
            min_samples_leaf=4,
            max_features="sqrt",
            class_weight="balanced",
            random_state=42,
            n_jobs=-1,
        )

        xgb_model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            scale_pos_weight=10,
            random_state=42,
            n_jobs=-1,
            eval_metric="logloss",
        )

        lgb_model = lgb.LGBMClassifier(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            class_weight="balanced",
            random_state=42,
            n_jobs=-1,
            verbose=-1,
        )

        gb = GradientBoostingClassifier(
            n_estimators=150, max_depth=5, learning_rate=0.05, subsample=0.8, random_state=42
        )

        # Meta-learner
        meta_learner = LogisticRegression(max_iter=1000, class_weight="balanced", random_state=42)

        # Stacking
        stacking_model = StackingClassifier(
            estimators=[("rf", rf), ("xgb", xgb_model), ("lgb", lgb_model), ("gb", gb)],
            final_estimator=meta_learner,
            cv=5,
            n_jobs=-1,
        )

        logger.info("   âœ… ModÃ¨le Stacking configurÃ©")
        logger.info("      - 4 base learners: RF, XGBoost, LightGBM, GB")
        logger.info("      - Meta-learner: LogisticRegression")
        logger.info("      - CV: 5 folds")

        return stacking_model

    def train_and_validate(
        self, X: pd.DataFrame, y: pd.Series
    ) -> Tuple[StackingClassifier, Dict[str, float]]:
        """EntraÃ®ne et valide le modÃ¨le."""
        logger.info("=" * 80)
        logger.info("ğŸ“ ENTRAÃNEMENT & VALIDATION")
        logger.info("=" * 80)

        # Split train/val
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        logger.info(f"   ğŸ“Š Train: {len(X_train):,} lignes")
        logger.info(f"   ğŸ“Š Val: {len(X_val):,} lignes")

        # Construire modÃ¨le
        model = self.build_stacking_model()

        # EntraÃ®ner
        logger.info("   ğŸ”„ EntraÃ®nement en cours...")
        model.fit(X_train, y_train)
        logger.info("   âœ… EntraÃ®nement terminÃ©")

        # PrÃ©dictions
        y_pred_proba = model.predict_proba(X_val)[:, 1]
        y_pred = model.predict(X_val)

        # MÃ©triques
        metrics = {
            "roc_auc": roc_auc_score(y_val, y_pred_proba),
            "accuracy": accuracy_score(y_val, y_pred),
            "precision": precision_score(y_val, y_pred, zero_division=0),
            "recall": recall_score(y_val, y_pred, zero_division=0),
        }

        logger.info("=" * 80)
        logger.info("ğŸ“Š MÃ‰TRIQUES VALIDATION")
        logger.info("=" * 80)
        logger.info(f"   ğŸ¯ ROC-AUC:   {metrics['roc_auc']:.4f}")
        logger.info(f"   âœ… Accuracy:  {metrics['accuracy']:.4f}")
        logger.info(f"   ğŸ² Precision: {metrics['precision']:.4f}")
        logger.info(f"   ğŸ“ˆ Recall:    {metrics['recall']:.4f}")

        # Validation seuil
        if metrics["roc_auc"] < self.min_roc_auc:
            logger.error(f"âŒ ROC-AUC {metrics['roc_auc']:.4f} < seuil {self.min_roc_auc}")
            logger.error("   Nouveau modÃ¨le REJETÃ‰")
            return None, metrics

        logger.info(f"âœ… ROC-AUC {metrics['roc_auc']:.4f} >= seuil {self.min_roc_auc}")
        logger.info("   Nouveau modÃ¨le VALIDÃ‰")

        return model, metrics

    def save_model(self, model: StackingClassifier, metrics: Dict[str, float]) -> Path:
        """Sauvegarde le nouveau modÃ¨le comme challenger."""
        logger.info("=" * 80)
        logger.info("ğŸ’¾ SAUVEGARDE MODÃˆLE")
        logger.info("=" * 80)

        if self.dry_run:
            logger.info("   â„¹ï¸  Mode DRY-RUN: pas de sauvegarde")
            return None

        # CrÃ©er dossier challenger
        self.challenger_dir.mkdir(parents=True, exist_ok=True)

        # Timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Sauvegarder modÃ¨le
        model_path = self.challenger_dir / "model.pkl"
        with open(model_path, "wb") as f:
            pickle.dump(model, f)

        logger.info(f"   âœ… ModÃ¨le sauvegardÃ©: {model_path}")

        # Metadata
        metadata = {
            "timestamp": timestamp,
            "datetime": datetime.now().isoformat(),
            "model_type": "stacking_ensemble",
            "version": "v1.1.0",  # Version challenger
            "metrics": metrics,
            "training": {
                "days_feedback": self.days,
                "min_roc_auc_threshold": self.min_roc_auc,
                "features_count": len(self.feature_columns),
            },
            "git_commit": self._get_git_commit(),
            "created_by": "train_online.py",
        }

        metadata_path = self.challenger_dir / "metadata.json"
        with open(metadata_path, "w") as f:
            json.dump(metadata, f, indent=2)

        logger.info(f"   âœ… Metadata sauvegardÃ©e: {metadata_path}")

        self.metadata = metadata

        return model_path

    def _get_git_commit(self) -> Optional[str]:
        """RÃ©cupÃ¨re le hash du commit Git actuel."""
        try:
            import subprocess

            result = subprocess.run(
                ["git", "rev-parse", "--short", "HEAD"], capture_output=True, text=True, check=True
            )
            return result.stdout.strip()
        except:
            return None

    def archive_old_champion(self):
        """Archive l'ancien modÃ¨le champion avant promotion."""
        logger.info("=" * 80)
        logger.info("ğŸ“¦ ARCHIVAGE ANCIEN CHAMPION")
        logger.info("=" * 80)

        if not (self.champion_dir / "model.pkl").exists():
            logger.info("   â„¹ï¸  Pas de champion existant Ã  archiver")
            return

        # CrÃ©er dossier archive avec timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_subdir = self.archive_dir / timestamp
        archive_subdir.mkdir(parents=True, exist_ok=True)

        # Copier champion â†’ archive
        shutil.copy(self.champion_dir / "model.pkl", archive_subdir / "model.pkl")

        if (self.champion_dir / "metadata.json").exists():
            shutil.copy(self.champion_dir / "metadata.json", archive_subdir / "metadata.json")

        logger.info(f"   âœ… Champion archivÃ© dans: {archive_subdir}")

    def run(self) -> bool:
        """ExÃ©cute le pipeline complet de retraining."""
        logger.info("â•”" + "=" * 78 + "â•—")
        logger.info("â•‘" + " " * 20 + "ğŸ”„ PIPELINE RETRAINING AUTOMATIQUE" + " " * 24 + "â•‘")
        logger.info("â•š" + "=" * 78 + "â•")
        logger.info("")

        try:
            # 1. Charger donnÃ©es originales
            original_df = self.load_original_training_data()

            # 2. Charger feedbacks
            feedback_df = self.load_feedback_data()

            if feedback_df is None:
                logger.warning("âš ï¸  Retraining annulÃ©: pas assez de feedbacks")
                return False

            # 3. Merger donnÃ©es
            merged_df = self.merge_data(original_df, feedback_df)

            # 4. PrÃ©parer features
            X, y = self.prepare_features(merged_df)

            # 5. EntraÃ®ner et valider
            model, metrics = self.train_and_validate(X, y)

            if model is None:
                logger.error("âŒ Validation Ã©chouÃ©e: modÃ¨le rejetÃ©")
                return False

            # 6. Sauvegarder
            model_path = self.save_model(model, metrics)

            if model_path:
                logger.info("=" * 80)
                logger.info("ğŸ‰ RETRAINING RÃ‰USSI!")
                logger.info("=" * 80)
                logger.info(f"   ğŸ“ Nouveau modÃ¨le: {model_path}")
                logger.info(f"   ğŸ¯ ROC-AUC: {metrics['roc_auc']:.4f}")
                logger.info("   â„¹ï¸  ModÃ¨le sauvegardÃ© comme CHALLENGER")
                logger.info("   ğŸ“ Prochaine Ã©tape: A/B Testing puis promotion si performant")
                logger.info("=" * 80)

            return True

        except Exception as e:
            logger.error(f"âŒ ERREUR FATALE: {e}", exc_info=True)
            return False


def main():
    """Point d'entrÃ©e principal."""
    parser = argparse.ArgumentParser(
        description="Pipeline de retraining automatique - Phase 8 Online Learning"
    )
    parser.add_argument(
        "--days", type=int, default=7, help="Nombre de jours de feedback Ã  inclure (dÃ©faut: 7)"
    )
    parser.add_argument(
        "--min-roc-auc",
        type=float,
        default=0.70,
        help="ROC-AUC minimum pour valider nouveau modÃ¨le (dÃ©faut: 0.70)",
    )
    parser.add_argument(
        "--min-samples",
        type=int,
        default=100,
        help="Nombre minimum de nouveaux Ã©chantillons requis (dÃ©faut: 100)",
    )
    parser.add_argument("--dry-run", action="store_true", help="Test sans sauvegarder le modÃ¨le")

    args = parser.parse_args()

    # CrÃ©er dossier logs
    Path("logs").mkdir(exist_ok=True)

    # Lancer retraining
    trainer = OnlineTrainer(
        days=args.days,
        min_roc_auc=args.min_roc_auc,
        min_new_samples=args.min_samples,
        dry_run=args.dry_run,
    )

    success = trainer.run()

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
